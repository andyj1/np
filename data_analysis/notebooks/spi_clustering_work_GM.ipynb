{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pathlib\n", "import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "from tqdm import tqdm\n", "import sys"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib.pylab as pl"]}, {"cell_type": "markdown", "metadata": {}, "source": ["set data path"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dir_path = pathlib.Path().absolute()  # \ud604\uc7ac \uc774 \ub178\ud2b8\ubd81 \ud30c\uc77c \uc704\uce58\n", "file = './MOM4_data_201229.csv'  # \ud604\uc7ac \uc774 \ub178\ud2b8\ubd81 \ud30c\uc77c \uae30\uc900 \ub514\ub809\ud1a0\ub9ac \uc704\uce58\uc5d0\uc11c \ub370\uc774\ud130\uc14b\uc758 \uc704\uce58\n", "data_path = os.path.join(dir_path, file)\n", "print('MOM4 data located at:', data_path)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["read data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = pd.read_csv(data_path, index_col=False).drop(['Unnamed: 0'], axis=1)\n", "df.reset_index(drop=True, inplace=True)\n", "assert df.isnull().sum().sum() == 0\n", "# find which (PartType, Orientation, Job) is missing"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dfgroups = df.groupby(['PartType', 'Orient.', 'Job'])\n", "reps = 15\n", "stencils = 5 * 5  # solder offset\n", "t = tqdm(dfgroups)\n", "for idx, (name, group) in enumerate(t):\n", "\tt.set_description(f'Checking: {name}')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\tchiptype, orient, jobtype = name\n", "\tif chiptype == 'R0402':\n", "\t\tcontinue\n", "\t# \uc911\ubcf5\ub418\ub294 job\uc5d0 \ub300\ud574 15\uac1c \uc548\ub418\uba74 \ud504\ub9b0\ud2b8\n", "\tjobcount = dict()\n", "\tfor index, row in group.iterrows():\n", "\t\tjob = row['Job']\n", "\t\ttry:\n", "\t\t\tjobcount[job] += 1\n", "\t\texcept:\n", "\t\t\tjobcount[job] = 1\n", "\tfor key, values in jobcount.items():\n", "\t\tif values < (stencils * reps):\n", "\t\t\tprint('Missing:\\t', chiptype, f'/ {orient} deg /', jobtype, ':', 375 - jobcount[key])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["find which CRD is missing"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n    <br>\n", "CRD: B if R0402, C if 0603, D if R1005<br>\n", "orient 0:  376-750 for each job<br>\n", "orient 90: 1-375 for each job<br>\n", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["pull dataframe with conditions as found above"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["missing_chip = {0: 'R0603-0-Job_2_2', 1: 'R1005-0-Job_8_5', 2: 'R1005-90-Job_0_3'}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["temp1 = df.loc[(df['PartType'] == 'R0603') & (df['Orient.'] == 0) & (df['Job'] == 'Job_2_2')]\n", "temp2 = df.loc[(df['PartType'] == 'R1005') & (df['Orient.'] == 0) & (df['Job'] == 'Job_8_5')]\n", "temp3 = df.loc[(df['PartType'] == 'R1005') & (df['Orient.'] == 90) & (df['Job'] == 'Job_0_3')]\n", "temps = [temp1, temp2, temp3]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["expected_crds_90deg = np.arange(1, 375, 1)\n", "expected_crds_0deg = np.arange(376, 750, 1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["t = tqdm(temps)\n", "for i, temp in enumerate(t):\n", "\tcrds_orig = temp['CRD'].values\n", "\tcrds = [int(crd[1:]) for crd in crds_orig]\n", "\torient = temp['Orient.'].values[0]\n", "\tchiptype = temp['PartType'].values[0]\n", "\tt.set_description(f'Checking: ({chiptype}, {orient}, {crds_orig[i]})')\n", "\tif orient == 0:\n", "\t\tfor item in expected_crds_0deg:\n", "\t\t\tif item not in crds:\n", "\t\t\t\tif chiptype == 'R0603':\n", "\t\t\t\t\tprint(f'Missing CRD in {missing_chip[i]}:\\tC{item}')\n", "\t\t\t\telif chiptype == 'R1005':\n", "\t\t\t\t\tprint(f'Missing CRD in {missing_chip[i]}:\\tD{item}')\n", "\telse:\n", "\t\tfor item in expected_crds_90deg:\n", "\t\t\tif item not in crds:\n", "\t\t\t\tif chiptype == 'R0603':\n", "\t\t\t\t\tprint(f'Missing CRD in {missing_chip[i]}:\\tC{item}')\n", "\t\t\t\telif chiptype == 'R1005':\n", "\t\t\t\t\tprint(f'Missing CRD in {missing_chip[i]}:\\tD{item}')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["missing_crd = {0: 'C395', 1: 'D492', 2: 'D143'}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["append columns: mean SPI x AND y"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if not 'SPI_X_AVG' in list(df.columns):\n", "\tavg_spi_x = df.loc[:, ['SPI_X1', 'SPI_X2']].mean(axis=1)\n", "\tavg_spi_y = df.loc[:, ['SPI_Y1', 'SPI_Y2']].mean(axis=1)\n", "\tdf.insert(11, 'SPI_X_AVG', avg_spi_x)\n", "\tdf.insert(12, 'SPI_Y_AVG', avg_spi_y)\n", "df['SPI_L_PERCENT'] = \"\"\n", "df['SPI_W_PERCENT'] = \"\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["temp1 = df.loc[(df['PartType'] == 'R0603') & (df['Orient.'] == 0) & (df['Job'] == 'Job_2_2')]\n", "temp2 = df.loc[(df['PartType'] == 'R1005') & (df['Orient.'] == 0) & (df['Job'] == 'Job_8_5')]\n", "temp3 = df.loc[(df['PartType'] == 'R1005') & (df['Orient.'] == 90) & (df['Job'] == 'Job_0_3')]\n", "temps = [temp1, temp2, temp3]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["missing_case = [['R0603',0,'Job_2_2'],['R1005',0,'Job_8_5'],['R1005',90,'Job_0_3']]\n", "# %%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## visualize (x, y)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["x1 = 'SPI_X1'<br>\n", "y1 = 'SPI_Y1'<br>\n", "x2 = 'SPI_X2'<br>\n", "y2 = 'SPI_Y2'"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["xavg = 'SPI_X_AVG'\n", "yavg = 'SPI_Y_AVG'"]}, {"cell_type": "markdown", "metadata": {}, "source": ["temp#_df: contains SPI_X_AVG and SPI_Y_AVG"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["temp1_df = temp1[[xavg, yavg]]\n", "temp2_df = temp2[[xavg, yavg]]\n", "temp3_df = temp3[[xavg, yavg]]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["clustering"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from collections import defaultdict"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def list_duplicates(seq):\n", "\ttally = defaultdict(list)\n", "\tfor i, item in enumerate(seq):\n", "\t\ttally[item].append(i)\n", "\treturn ((key, locs) for key, locs in tally.items() if len(locs) > 1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["1. scikit learn - Kmeans"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.cluster import KMeans"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["missing_sample = dict()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig = plt.figure(figsize=(18, 5), facecolor='white')\n", "temp_dfs = [temp1_df, temp2_df, temp3_df]\n", "# for temp_idx, temp_df in enumerate(temp_dfs):\n", "jobs = ['Job_%d_%d'%(i,j) for i in range(9) for j in range(9)]\n", "temp_idx = 0\n", "for chip_type in ['R0402','R0603','R1005'] :\n", "\tfor orient in [0, 90] :\n", "\t\tfor job in jobs :\n", "\t\t\ttemp_df = df.loc[(df['PartType'] == chip_type) & (df['Orient.'] == orient) & (df['Job'] == job)]\n", "\t\t\ttemp_df = temp_df[['SPI_L', 'SPI_W']]\n", "\t\t\tkmeans = KMeans(n_clusters=25).fit(temp_df)\n", "\t\t\tcentroids = kmeans.cluster_centers_\n", "\t\t\tlabel = kmeans.labels_.astype(int)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t\t\tl_means = KMeans(n_clusters=5).fit(centroids[:, 0].reshape(-1,1))\n", "\t\t\tl_centroids = l_means.cluster_centers_\n", "\t\t\t_label = np.argsort(l_centroids.reshape(-1))\n", "\t\t\t_label = np.asarray(range(5))[_label]\n", "\t\t\t_l_label = l_means.labels_.astype(int)\n", "\t\t\tl_label = _label[_l_label]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t\t\tw_means = KMeans(n_clusters=5).fit(centroids[:, 1].reshape(-1,1))\n", "\t\t\tw_centroids = w_means.cluster_centers_\n", "\t\t\t_label = np.argsort(w_centroids.reshape(-1))\n", "\t\t\t_label = np.asarray(range(5))[_label]\n", "\t\t\t_w_label = w_means.labels_.astype(int)\n", "\t\t\tw_label = _label[_w_label]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t\t\tdf.set_value(temp_df.index.get_values(),'SPI_L_PERCENT',10 * (l_label[label] - 2))\n", "\t\t\tdf.set_value(temp_df.index.get_values(),'SPI_W_PERCENT',10 * (w_label[label] - 2))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t\t\tif [chip_type, orient, job] in missing_case :\n", "\t\t\t\tmissing_sample[temp_idx] = []\n", "\t\t\t\tfor dup in sorted(list_duplicates(kmeans.labels_)):\n", "\t\t\t\t\tif len(temp_df.iloc[dup[1], :]) < 15:\n", "\t\t\t\t\t\tmissing_sample[temp_idx] = (dup[0], dup[1])\n", "\t\t\t\t\t\tchip_orient_job = missing_chip[temp_idx]\n", "\t\t\t\t\t\tprint(\n", "\t\t\t\t\t\t\tf'{chip_orient_job}: centroid {dup[0]} (Count: {len(temp_df.iloc[dup[1], :])})')  # ' \\n {temp_df.iloc[dup[1],:]} \\n') # lists corresponding row indices for each centroid\n", "\t\t\t\t\telse:\n", "\t\t\t\t\t\tcontinue\n", "\t\t\t\ttemp_idx += 1\n", "\t\t\t# ax = fig.add_subplot(1, 3, temp_idx)\n", "\t\t\t# ax.scatter(temp_df[xavg], temp_df[yavg], c=kmeans.labels_.astype(float), s=50, alpha=0.5, label='SPI_AVG')\n", "\t\t\t# ax.scatter(centroids[:, 0], centroids[:, 1], c='red', s=50, label='centroid')\n", "\t\t\t# ax.set_xlabel(f'{xavg} (\\u03BCm)')\n", "\t\t\t# ax.set_ylabel(f'{yavg} (\\u03BCm)')\n", "\t\t\t# ax.legend(loc='upper right')\n", "\t\t\t# ax.grid()\n", "\t\t\t# ax.set_title(missing_chip[temp_idx])\n", "# plt.show()\n", "# fig.savefig('./stencils.png')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["check: (parttype, orient, job) sample"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print('Sample:\\n')\n", "print(missing_chip[0])\n", "print(temps[0].head(1))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["check centroid values<br>\n", "missing sample contains (centroid number, index in temp_dfs[i] for the centroid)<br>\n", "temp_dfs contains dataframe corresponding to the chosen indices (for the centroids)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print('Centroids:\\n')\n", "for i, (k, v) in enumerate(missing_sample.items()):\n", "\tprint(f'{missing_chip[k]}:\\n(index: {v}), \\n(df: {temp_dfs[i].iloc[v[1], :].head(1)})')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["imputation: KNN Imputer(2 neighbors)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.impute import KNNImputer"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["imputer = KNNImputer(n_neighbors=2, weights=\"uniform\")\n", "df_temp_save = df.copy()\n", "# df_temp_save = df.copy().drop(columns=['SPI_VOLUME1', 'SPI_VOLUME2', 'SPI_R','PRE_R','POST_R','SPI_VOLUME_DIFF'])\n", "for i in range(len(missing_sample)):\n", "\t# tadd a nan row, impute NaN, add to original by index, reset index\n", "\ttmp = temps[i].iloc[missing_sample[i][1], :].append(pd.Series(dtype=float), ignore_index=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t# columns to impute:\n", "\tcols_to_impute = ['X', 'Y', 'SPI_VOLUME_MEAN', 'SPI_X1', 'SPI_Y1', 'SPI_X2', 'SPI_Y2', 'SPI_X_AVG', 'SPI_Y_AVG', \\\n", "\t\t\t\t\t  'SPI_L1', 'SPI_W1', 'SPI_L2', 'SPI_W2', 'SPI_L', 'SPI_W', \\\n", "\t\t\t\t\t  'PRE_X', 'PRE_Y', 'PRE_A', 'PRE_L', 'PRE_W', \\\n", "\t\t\t\t\t  'POST_X', 'POST_Y', 'POST_A', 'POST_L', 'POST_W', 'Orient.']\n", "\t# drop CRD and PartType for imputation\n", "\ttmp = tmp[cols_to_impute]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\ttransformed = pd.DataFrame(imputer.fit_transform(tmp), columns=cols_to_impute).round(3)\n", "\timputed = transformed.iloc[len(transformed) - 1, :]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\tcentroid_index_start = temp_dfs[i].iloc[missing_sample[i][1], :].index[0]\n", "\tcentroid_index_end = temp_dfs[i].iloc[missing_sample[i][1], :].index[-1]\n", "\tprint('size changed: from', len(temp_dfs[i].iloc[missing_sample[i][1], :]), \\\n", "\t\t  'to', len(transformed), '/ indices corresp. to each centroid (from orig df): from', centroid_index_start, \\\n", "\t\t  'to', centroid_index_end)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\tjob, parttype, chipl, chipw, orient = df_temp_save.iloc[centroid_index_end, :][\n", "\t\t['Job', 'PartType', 'Chip_L', 'Chip_W', 'Orient.']]\n", "\tfor col in list(df_temp_save.columns):\n", "\t\tif col not in cols_to_impute:\n", "\t\t\t# append random value to these columns\n", "\t\t\tif col == 'Job':\n", "\t\t\t\timputed[col] = job\n", "\t\t\telif col == 'PartType':\n", "\t\t\t\timputed[col] = parttype\n", "\t\t\telif col == 'Chip_L':\n", "\t\t\t\timputed[col] = chipl\n", "\t\t\telif col == 'Chip_W':\n", "\t\t\t\timputed[col] = chipw\n", "\t\t\telif col == 'Orient.':\n", "\t\t\t\timputed[col] = orient\n", "\t\t\telif col == 'CRD':\n", "\t\t\t\timputed[col] = missing_crd[i]\n", "\t\t\telse:\n", "\t\t\t\timputed[col] = np.nan\n", "\tassert len(imputed.index) == len(list(df_temp_save.columns))\n", "\t#     print(imputed)\n", "\tdf_temp_save = df_temp_save.append(imputed, ignore_index=True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["scan for missing (parttype, orientation, job):<br>\n", ">> if none printed, then none missing!<br>\n", ">> all 15 reps, 25 stencil jobs, 81 chip jobs present"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dfgroups = df_temp_save.groupby(['PartType', 'Orient.', 'Job'])\n", "reps = 3 * 5  # chip offset\n", "stencils = 5 * 5  # solder offset\n", "t = tqdm(dfgroups)\n", "for idx, (name, group) in enumerate(t):\n", "\tt.set_description(f'Checking: {name}')\n", "\tchiptype, orient, jobtype = name\n", "\t# \uc911\ubcf5\ub418\ub294 job\uc5d0 \ub300\ud574 15\uac1c \uc548\ub418\uba74 \ud504\ub9b0\ud2b8\n", "\tjobcount = dict()\n", "\tfor index, row in group.iterrows():\n", "\t\tjob = row['Job']\n", "\t\ttry:\n", "\t\t\tjobcount[job] += 1\n", "\t\texcept:\n", "\t\t\tjobcount[job] = 1\n", "\tfor key, values in jobcount.items():\n", "\t\tif values < (stencils * reps):\n", "\t\t\tprint(chiptype, f'/ {orient} deg /', jobtype, ':', jobcount[key])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df_temp_save = df_temp_save[['X', 'Y', 'SPI_VOLUME_MEAN', 'SPI_X1', 'SPI_Y1', 'SPI_X2', 'SPI_Y2', 'SPI_X_AVG', 'SPI_Y_AVG', \\\n", "\t\t\t\t\t  'SPI_L1', 'SPI_W1', 'SPI_L2', 'SPI_W2', 'SPI_L', 'SPI_W', 'SPI_L_PERCENT', 'SPI_W_PERCENT', \\\n", "\t\t\t\t\t  'PRE_X', 'PRE_Y', 'PRE_A', 'PRE_L', 'PRE_W', \\\n", "\t\t\t\t\t  'POST_X', 'POST_Y', 'POST_A', 'POST_L', 'POST_W', 'Orient.']]\n", "# df_imputed = df_temp_save.drop(columns=['SPI_VOLUME1', 'SPI_VOLUME2', 'SPI_R', 'PRE_R', 'POST_R', 'SPI_VOLUME_DIFF'])\n", "df_temp_save.to_csv('./test.csv')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["df_imputed.head(5)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}